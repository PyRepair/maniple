The issue description is:

```text
`from keras.preprocessing.text import Tokenizer

texts = ['Just any text.']
t = Tokenizer(split="any")
t.fit_on_texts(texts)
print(t.word_index)`

throws an exception:
ValueError: the first two maketrans arguments must have equal length
```
